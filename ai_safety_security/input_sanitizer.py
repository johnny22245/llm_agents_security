import re
import autogen

class InputSanitizer:
    """
    A module to sanitize input text by detecting and replacing personal data
    like PERSON names, AGE, LOCATION, etc., with placeholders, while leaving pronouns intact.
    """

    def __init__(self, model_name: str = "gpt-4"):
        """
        Initializes the InputSanitizer with the autogen model.

        Args:
            model_name (str): The LLM model to use (default is gpt-4).
        """
        # Configure the agent with the provided GPT model
        config_list = autogen.config_list_from_json(
            env_or_file="OAI_CONFIG_LIST.json"
        )
        self.agent = autogen.AssistantAgent(
            name="input-sanitizer",
            llm_config={
                "config_list": config_list
            },
            code_execution_config={
                "work_dir": "coding",
                "use_docker": False
            }
        )
    
    """Check for famous personality check to refrain from marking as personal data"""
    def _is_famous_person(self, entity_text: str) -> bool:
        """
        Checks if the entity is a famous historical figure using an LLM query.
        
        Args:
            entity_text (str): The detected entity text.

        Returns:
            bool: True if the entity is a known historical figure, False otherwise.
        """
        prompt = f"Is '{entity_text}' a famous person or historical figure? reply only as yes/no"
        response = self.agent.generate_reply(messages=[{"role": "user", "content": prompt}])
        print("Generated id famous: ", response)
        # If the response contains confirmation of fame, return True
        if "yes" in response.lower():
            return True
        else:
            return False
    
    """Check for relatable to refrain from marking as personal data"""
    def _is_relatable(self, entity_text: str, context: str) -> bool:
        """
        Checks if the detected entity is contextually relevant to the user's query or answer.

        Args:
            entity_text (str): The detected entity text.
            context (str): The user query or context to check the relevance of the entity.

        Returns:
            bool: True if the entity is relevant to the context, False otherwise.
        """
        prompt = f"Is '{entity_text}' relevant and necessary to the answer any of the following query in the context: {context} Reply only as yes/no"
        
        # Query the LLM with the context and entity to check relevance
        response = self.agent.generate_reply(messages=[{"role": "user", "content": prompt}])
        print(f"Generated response for relevance check of entity '{entity_text}': ", response)
        
        # Check if the entity is considered relevant to the context
        if "yes" in response.lower():
            return True
        else:
            return False
    
    def _is_personal_data(self, entity_text: str, context_query: str) -> bool:
        """
        Checks if the entity is personal data (e.g., name, age, address, etc.) by querying the LLM.
        
        Args:
            entity_text (str): The detected entity text.

        Returns:
            bool: True if the entity is personal data, False otherwise.
        """
        prompt = f"Is '{entity_text}' personal data such as a name, age, or location? reply only in yes/no"
        response = self.agent.generate_reply(messages=[{"role": "user", "content": prompt}])
        
        
        # If the response indicates it's personal data, return True
        if "yes" in response.lower():
            #famous person check & relatable check
            if self._is_famous_person(entity_text) or self._is_relatable(entity_text, context_query):
                print(entity_text)
                return False
            return True
        else:
            return False
        
    def sanitize(self, text: str) -> str:
        """
        Detects personal data like PERSON names, AGE, LOCATION, etc., in the input text
        and replaces them with autogenerated placeholders using an LLM agent,
        while leaving pronouns like "I", "my", etc., intact.

        Args:
            text (str): The input text to be sanitized.

        Returns:
            str: The sanitized text with autogenerated placeholders.
        """
        # Define a list of pronouns to leave intact
        pronouns = ["I", "my", "me", "we", "our", "us", "you", "your", "he", "his", "him", "she", "her", "they", "their", "them"]

        # Example of named entity recognition using simple regex patterns for different types of entities
        # In production, replace this with a proper NER model or library like spaCy for better detection
        entities = re.findall(r"\b([A-Z][a-z]+(?: [A-Z][a-z]+)*)\b", text)  # Detect capitalized words
        
        # Loop over the detected entities and replace them using the LLM
        sanitized_text = text
        for entity in entities:
            # Skip if the entity is a pronoun
            if entity.lower() in pronouns:
                continue
            
            # Check if the entity is considered personal data (e.g., name, age, location, etc.)
            if self._is_personal_data(entity, text):
                # Replace personal data with a generic placeholder
                placeholder = f"<PERSONAL_DATA>"
            else:
                # Leave non-personal data intact (for simplicity, here we assume all other words are non-personal)
                placeholder = entity

            # Replace the entity with the placeholder in the text
            sanitized_text = sanitized_text.replace(entity, placeholder)

        return sanitized_text
